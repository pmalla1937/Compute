{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1akD2SPd6su6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "import os, time\n",
        "\n",
        "np.random.seed(2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating data\n",
        "T = 20\n",
        "L = 1000\n",
        "N = 100\n",
        "\n",
        "x = np.empty((N, L), 'int64')\n",
        "x[:] = np.array(range(L)) + np.random.randint(-4 * T, 4 * T, N).reshape(N, 1)\n",
        "data = np.sin(x / 1.0 / T).astype('float64')\n",
        "torch.save(data, open('traindata.pt', 'wb'))\n",
        "\n",
        "# Number of steps for training\n",
        "steps = 1"
      ],
      "metadata": {
        "id": "vutabMVaFkpt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Sequence(nn.Module):\n",
        "    def __init__(self, device):\n",
        "        super(Sequence, self).__init__()\n",
        "        # creating cells lstm1, lstm2, linear layer for prediction\n",
        "        self.lstm1 = nn.LSTMCell(1, 51)\n",
        "        self.lstm2 = nn.LSTMCell(51, 51)\n",
        "        self.linear = nn.Linear(51, 1)\n",
        "        self.device = device\n",
        "      # we defining forward propagation \n",
        "    def forward(self, input, future = 0):\n",
        "        outputs = []\n",
        "        h_t = torch.zeros(input.size(0), 51, dtype=torch.double, device=self.device)\n",
        "        c_t = torch.zeros(input.size(0), 51, dtype=torch.double, device=self.device)\n",
        "        h_t2 = torch.zeros(input.size(0), 51, dtype=torch.double, device=self.device)\n",
        "        c_t2 = torch.zeros(input.size(0), 51, dtype=torch.double, device=self.device)\n",
        "       # it takes input\n",
        "        for input_t in input.split(1, dim=1):\n",
        "            h_t, c_t = self.lstm1(input_t, (h_t, c_t))\n",
        "            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))\n",
        "            output = self.linear(h_t2)\n",
        "            outputs += [output]\n",
        "           # it gives us output\n",
        "        for i in range(future):# if we should predict the future\n",
        "            h_t, c_t = self.lstm1(output, (h_t, c_t))\n",
        "            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))\n",
        "            output = self.linear(h_t2)\n",
        "            outputs += [output]\n",
        "        outputs = torch.cat(outputs, dim=1)\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "FGW01w4f66W4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_on(steps, device):\n",
        "  # build the model\n",
        "  seq = Sequence(device)\n",
        "  seq.double()\n",
        "  criterion = nn.MSELoss()\n",
        "  # use LBFGS as optimizer since we can load the whole data to train\n",
        "  optimizer = optim.LBFGS(seq.parameters(), lr=0.8)\n",
        "  # export model to corresponding device\n",
        "  seq.to(device)\n",
        "\n",
        "  # set random seed to 0\n",
        "  np.random.seed(0)\n",
        "  torch.manual_seed(0)\n",
        "  # load data and make training set\n",
        "  data = torch.load('traindata.pt')\n",
        "  input = torch.from_numpy(data[3:, :-1])\n",
        "  target = torch.from_numpy(data[3:, 1:])\n",
        "  test_input = torch.from_numpy(data[:3, :-1])\n",
        "  test_target = torch.from_numpy(data[:3, 1:])\n",
        "  # exporting the variables to specific device memory\n",
        "  input = input.to(device)\n",
        "  target = target.to(device)\n",
        "  test_input = test_input.to(device)\n",
        "  test_target = test_target.to(device)\n",
        "\n",
        "  # create directories to store the predictions\n",
        "  os.makedirs(device, exist_ok=True)\n",
        "\n",
        "  #begin initializing to train\n",
        "  time_taken = 0\n",
        "  train_losses = []\n",
        "  test_losses = []\n",
        "  for i in range(steps):\n",
        "      # print('STEP: ', i)\n",
        "      def closure():\n",
        "          optimizer.zero_grad()\n",
        "          out = seq(input)\n",
        "          loss = criterion(out, target)\n",
        "          # print('loss:', loss.item())\n",
        "          train_losses.append(loss.item())\n",
        "          loss.backward()\n",
        "          return loss\n",
        "      optimizer.step(closure)\n",
        "      # optimizer.step()\n",
        "      # print(\"optdone\")\n",
        "      # begin to predict, no need to track gradient here\n",
        "      tic = time.time()\n",
        "      with torch.no_grad():\n",
        "          future = 1000\n",
        "          pred = seq(test_input, future=future)\n",
        "          loss = criterion(pred[:, :-future], test_target)\n",
        "          # print('test loss:', loss.item())\n",
        "          test_losses.append(loss.item())\n",
        "          y = pred.detach().cpu().numpy()\n",
        "      toc = time.time()\n",
        "      time_taken += toc - tic\n",
        "      # draw the result\n",
        "      plt.figure(figsize=(30,10))\n",
        "      plt.title('Predict future values for time sequences\\n(Dashlines are predicted values)', fontsize=30)\n",
        "      plt.xlabel('x', fontsize=20)\n",
        "      plt.ylabel('y', fontsize=20)\n",
        "      plt.xticks(fontsize=20)\n",
        "      plt.yticks(fontsize=20)\n",
        "      def draw(yi, color):\n",
        "          plt.plot(np.arange(input.size(1)), yi[:input.size(1)], color, linewidth = 2.0)\n",
        "          plt.plot(np.arange(input.size(1), input.size(1) + future), yi[input.size(1):], color + ':', linewidth = 2.0)\n",
        "      draw(y[0], 'r')\n",
        "      draw(y[1], 'g')\n",
        "      draw(y[2], 'b')\n",
        "      plt.savefig('./{}/predict{}.png'.format(device, i))\n",
        "      plt.close()\n",
        "\n",
        "  time_taken = time_taken/steps\n",
        "\n",
        "  return time_taken, train_losses, test_losses"
      ],
      "metadata": {
        "id": "OkkJ_1umAN2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training on CPU\n",
        "time_take_cpu, train_losses_cpu, test_losses_cpu = run_on(steps, \"cpu\")\n",
        "print(\"Time taken on CPU: {}s\".format(np.round(time_take_cpu, 3)))\n",
        "# Training on GPU\n",
        "time_take_gpu, train_losses_gpu, test_losses_gpu = run_on(steps, \"cuda:0\")\n",
        "print(\"Time taken on GPU: {}s\".format(np.round(time_take_gpu, 3)))"
      ],
      "metadata": {
        "id": "6jrM0GC9C63A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75b43cd3-a281-43f6-9645-c9f0f5217c04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken on CPU: 0.267s\n",
            "Time taken on GPU: 0.308s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting CPU vs GPU training loss\n",
        "plt.figure()\n",
        "plt.title('Comparing Training Loss between CPU and GPU', fontsize=30)\n",
        "plt.xlabel('#Iterations', fontsize=20)\n",
        "plt.ylabel('Loss', fontsize=20)\n",
        "plt.xticks(fontsize=20)\n",
        "plt.yticks(fontsize=20)\n",
        "plt.plot(train_losses_cpu, label=\"CPU\")\n",
        "plt.plot(train_losses_gpu, label=\"GPU\")\n",
        "plt.legend()\n",
        "plt.savefig('train_comparision.pdf', bbox_inches='tight')\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "ihlDxlkxD9t3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}